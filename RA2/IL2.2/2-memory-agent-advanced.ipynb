{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sistemas de Memoria Avanzados en LangChain\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender las limitaciones de la gestión manual de la memoria.\n",
    "- Aprender a usar las clases de memoria de LangChain para automatizar el historial de chat.\n",
    "- Implementar `ConversationBufferMemory` para un historial completo.\n",
    "- Implementar `ConversationBufferWindowMemory` para limitar el tamaño del historial.\n",
    "- Implementar `ConversationSummaryMemory` para resumir conversaciones y ahorrar tokens.\n",
    "- Entender el puente hacia la planificación de agentes.\n",
    "\n",
    "## El Problema con la Memoria Manual\n",
    "\n",
    "En el notebook anterior, le dimos memoria a nuestro agente gestionando manualmente una lista `chat_history`. Aunque funcional, este enfoque tiene dos grandes inconvenientes:\n",
    "\n",
    "1.  **Gestión Tediosa**: Actualizar la lista manualmente después de cada interacción es propenso a errores y no es escalable.\n",
    "2.  **Límite de Contexto**: Enviar el historial completo en cada llamada consume tokens rápidamente. En conversaciones largas, esto puede exceder el límite de contexto del modelo, provocando errores o un alto costo.\n",
    "\n",
    "LangChain resuelve esto con un sistema de **clases de Memoria** que automatizan el proceso y ofrecen estrategias para gestionar historiales largos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instalación y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai openai wikipedia -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM de LangChain configurado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wikipedia\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Configurar el idioma de Wikipedia\n",
    "wikipedia.set_lang(\"es\")\n",
    "\n",
    "# Configuración del LLM\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        openai_api_base=os.environ.get(\"GITHUB_BASE_URL\"),\n",
    "        openai_api_key=os.environ.get(\"GITHUB_TOKEN\"),\n",
    "        temperature=0\n",
    "    )\n",
    "    print(\"✅ LLM de LangChain configurado.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error configurando el LLM: {e}\")\n",
    "    llm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Agente y Herramientas (Sin Cambios)\n",
    "\n",
    "Reutilizamos el mismo agente y herramientas. La innovación estará en cómo gestionamos la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Agente y herramientas listos.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool, create_openai_tools_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "\n",
    "@tool\n",
    "def get_wikipedia_summary(query: str) -> str:\n",
    "    \"\"\"Busca en Wikipedia un tema y devuelve un resumen de 2 frases. Útil para obtener información sobre personas, lugares o conceptos.\"\"\"\n",
    "    try:\n",
    "        return wikipedia.summary(query, sentences=2)\n",
    "    except Exception as e:\n",
    "        return f\"Ocurrió un error: {e}\"\n",
    "\n",
    "tools = [get_wikipedia_summary]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"✅ Agente y herramientas listos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Automatizando con `ConversationBufferMemory`\n",
    "\n",
    "Esta es la memoria más básica. Simplemente almacena todos los mensajes en una variable (el \"buffer\") y los pasa en cada llamada. Replica lo que hicimos manualmente, pero de forma automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# memory_key debe coincidir con la variable de entrada en el prompt ('chat_history')\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "def chat_with_agent_buffer(query: str):\n",
    "    # Carga el historial de la memoria\n",
    "    history = memory.load_memory_variables({})[\"chat_history\"]\n",
    "    \n",
    "    # Invoca al agente con el historial\n",
    "    response = agent_executor.invoke({\"input\": query, \"chat_history\": history})\n",
    "    \n",
    "    # Guarda el nuevo par de pregunta/respuesta en la memoria\n",
    "    memory.save_context({\"input\": query}, {\"output\": response[\"output\"]})\n",
    "    \n",
    "    return response[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera pregunta...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_wikipedia_summary` with `{'query': 'Marte'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giocrisraigodoy/Documents/DUOC/Semestre_2025_2/Ing. Soluciones de IA/tutorial_ingenieria_de_soluciones_ia/Ingenier-a-de-Soluciones-con-Inteligencia-Artificial/.venv/lib/python3.12/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/giocrisraigodoy/Documents/DUOC/Semestre_2025_2/Ing. Soluciones de IA/tutorial_ingenieria_de_soluciones_ia/Ingenier-a-de-Soluciones-con-Inteligencia-Artificial/.venv/lib/python3.12/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mOcurrió un error: \"Marte\" may refer to: \n",
      "Marte (planeta)\n",
      "Marte (mitología)\n",
      "hierro\n",
      "Marte (Velázquez)\n",
      "Marte, el portador de la guerra\n",
      "The Martian\n",
      "Marte (serie de televisión)\n",
      "«Marte» (canción)\n",
      "Marte (Coahuila)\n",
      "Marte (Nigeria)\n",
      "Club Deportivo Atlético Marte\n",
      "Club Deportivo Marte\n",
      "Wikcionario\n",
      "Diccionario de la Real Academia Española\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_wikipedia_summary` with `{'query': 'Marte planeta'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mMarte es el cuarto planeta en orden de distancia al Sol y el segundo más pequeño del sistema solar, después de Mercurio. Recibió su nombre en homenaje al homónimo dios de la guerra de la mitología romana (Ares en la mitología griega), y también es conocido como «el planeta rojo»​​ debido a la apariencia rojiza​ que le confiere el óxido de hierro predominante en su superficie.\u001b[0m\u001b[32;1m\u001b[1;3mMarte es el cuarto planeta en distancia al Sol y el segundo más pequeño del sistema solar, después de Mercurio. Conocido como \"el planeta rojo\" por el óxido de hierro que domina su superficie, debe su nombre al dios de la guerra de la mitología romana.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Respuesta 1: Marte es el cuarto planeta en distancia al Sol y el segundo más pequeño del sistema solar, después de Mercurio. Conocido como \"el planeta rojo\" por el óxido de hierro que domina su superficie, debe su nombre al dios de la guerra de la mitología romana.\n",
      "Segunda pregunta de seguimiento...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSí, Marte tiene dos lunas pequeñas llamadas **Fobos** y **Deimos**. Ambas son irregulares en forma y se cree que podrían ser asteroides capturados por la gravedad de Marte. Fobos es la más grande y cercana al planeta, mientras que Deimos es más pequeña y está más alejada.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Respuesta 2: Sí, Marte tiene dos lunas pequeñas llamadas **Fobos** y **Deimos**. Ambas son irregulares en forma y se cree que podrían ser asteroides capturados por la gravedad de Marte. Fobos es la más grande y cercana al planeta, mientras que Deimos es más pequeña y está más alejada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Primera pregunta...\")\n",
    "response1 = chat_with_agent_buffer(\"Háblame del planeta Marte\")\n",
    "print(f\"Respuesta 1: {response1}\")\n",
    "\n",
    "print(\"Segunda pregunta de seguimiento...\")\n",
    "response2 = chat_with_agent_buffer(\"¿Tiene alguna luna?\")\n",
    "print(f\"Respuesta 2: {response2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, la función `chat_with_agent_buffer` ahora se encarga de cargar y guardar el historial, haciendo el proceso mucho más limpio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gestionando el Contexto con `ConversationBufferWindowMemory`\n",
    "\n",
    "Para evitar que el historial crezca sin control, podemos usar `ConversationBufferWindowMemory`. Esta memoria solo conserva un número `k` de las últimas interacciones.\n",
    "\n",
    "Esto es un buen equilibrio entre tener contexto y no sobrecargar al LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# Creamos una nueva memoria, esta vez con k=1 (solo recuerda el último par de mensajes)\n",
    "memory_window = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "def chat_with_agent_window(query: str):\n",
    "    history = memory_window.load_memory_variables({})[\"chat_history\"]\n",
    "    response = agent_executor.invoke({\"input\": query, \"chat_history\": history})\n",
    "    memory_window.save_context({\"input\": query}, {\"output\": response[\"output\"]})\n",
    "    return response[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta 1: ¿Quién fue Albert Einstein?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_wikipedia_summary` with `{'query': 'Albert Einstein'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAlbert Einstein pronunciación en alemán: /ˈalbɐt ˈaɪnʃtaɪn/ ();​ (Ulm, Imperio alemán, 14 de marzo de 1879-Princeton, Estados Unidos, 18 de abril de 1955) fue un físico alemán de origen judío, nacionalizado después suizo, austriaco y estadounidense. Se le considera el científico más importante, conocido y popular del siglo XX.​​\n",
      "En 1905, cuando era un joven físico desconocido, empleado en la Oficina de Patentes de Berna, publicó su teoría de la relatividad especial.\u001b[0m\u001b[32;1m\u001b[1;3mAlbert Einstein (1879-1955) fue un físico alemán de origen judío, nacionalizado suizo, austriaco y estadounidense, considerado el científico más importante y popular del siglo XX. En 1905, mientras trabajaba en la Oficina de Patentes de Berna, publicó su teoría de la relatividad especial.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Pregunta 2: ¿Y Niels Bohr?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_wikipedia_summary` with `{'query': 'Niels Bohr'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNiels Henrik David Bohr (Copenhague, 7 de octubre de 1885-Copenhague, 18 de noviembre de 1962) fue un físico danés que contribuyó en la comprensión del átomo y la mecánica cuántica. Fue galardonado con el Premio Nobel de Física en 1922.​​\n",
      "\n",
      "\n",
      "== Biografía ==\n",
      "\n",
      " \n",
      "\n",
      "Nació en Copenhague, hijo de Christian Bohr, un devoto luterano y catedrático de fisiología en la universidad de la ciudad, y Ellen Adler, miembro de una adinerada familia judía de gran importancia en la banca danesa y en los «círculos del Parlamento».\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_wikipedia_summary` with `{'query': 'Albert Einstein'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAlbert Einstein pronunciación en alemán: /ˈalbɐt ˈaɪnʃtaɪn/ ();​ (Ulm, Imperio alemán, 14 de marzo de 1879-Princeton, Estados Unidos, 18 de abril de 1955) fue un físico alemán de origen judío, nacionalizado después suizo, austriaco y estadounidense. Se le considera el científico más importante, conocido y popular del siglo XX.​​\n",
      "En 1905, cuando era un joven físico desconocido, empleado en la Oficina de Patentes de Berna, publicó su teoría de la relatividad especial.\u001b[0m\u001b[32;1m\u001b[1;3mNiels Bohr (1885-1962) fue un físico danés que realizó importantes contribuciones a la comprensión del átomo y la mecánica cuántica. Fue galardonado con el Premio Nobel de Física en 1922.\n",
      "\n",
      "Albert Einstein (1879-1955) fue un físico alemán de origen judío, considerado el científico más importante y popular del siglo XX. En 1905, publicó su teoría de la relatividad especial mientras trabajaba en la Oficina de Patentes de Berna.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Pregunta 3: ¿De qué trataba la primera pregunta que te hice?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLa primera pregunta que me hiciste fue: \"¿Quién fue Albert Einstein?\" Querías saber sobre su vida o contribuciones.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Respuesta 3: La primera pregunta que me hiciste fue: \"¿Quién fue Albert Einstein?\" Querías saber sobre su vida o contribuciones.\n"
     ]
    }
   ],
   "source": [
    "print(\"Pregunta 1: ¿Quién fue Albert Einstein?\")\n",
    "chat_with_agent_window(\"¿Quién fue Albert Einstein?\")\n",
    "\n",
    "print(\"Pregunta 2: ¿Y Niels Bohr?\")\n",
    "chat_with_agent_window(\"¿Y Niels Bohr?\")\n",
    "\n",
    "print(\"Pregunta 3: ¿De qué trataba la primera pregunta que te hice?\")\n",
    "response3 = chat_with_agent_window(\"¿De qué trataba la primera pregunta que te hice?\")\n",
    "print(f\"Respuesta 3: {response3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El agente probablemente no podrá responder a la tercera pregunta, porque con `k=1`, la interacción sobre Einstein ya fue descartada de la memoria para dar paso a la de Niels Bohr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ahorrando Tokens con `ConversationSummaryMemory`\n",
    "\n",
    "Esta es la estrategia más avanzada. En lugar de guardar los mensajes completos, utiliza un LLM para crear un resumen de la conversación a medida que avanza. En cada nueva interacción, el resumen se actualiza y se pasa como contexto.\n",
    "\n",
    "Es ideal para conversaciones muy largas donde los detalles específicos se vuelven menos importantes que el contexto general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/tr7q4l9942176xmsld0751n40000gn/T/ipykernel_31087/1927192588.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory_summary = ConversationSummaryMemory(llm=llm, memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "# Esta memoria necesita un LLM para hacer los resúmenes\n",
    "memory_summary = ConversationSummaryMemory(llm=llm, memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "def chat_with_agent_summary(query: str):\n",
    "    history = memory_summary.load_memory_variables({})[\"chat_history\"]\n",
    "    response = agent_executor.invoke({\"input\": query, \"chat_history\": history})\n",
    "    memory_summary.save_context({\"input\": query}, {\"output\": response[\"output\"]})\n",
    "    return response[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta 1: Necesito organizar un viaje a Japón. ¿Cuál es la mejor época para ir?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_wikipedia_summary` with `{'query': 'mejor época para viajar a Japón'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mOcurrió un error: Page id \"mejor época para villar a japón\" does not match any pages. Try another id!\u001b[0m\u001b[32;1m\u001b[1;3mLa mejor época para viajar a Japón depende de tus intereses, pero generalmente se recomienda:\n",
      "\n",
      "1. **Primavera (marzo a mayo):** Es famosa por los cerezos en flor (sakura), especialmente a finales de marzo y principios de abril. El clima es templado y agradable.\n",
      "\n",
      "2. **Otoño (septiembre a noviembre):** Es ideal para disfrutar del follaje otoñal, con colores vibrantes en los árboles. También tiene un clima fresco y cómodo.\n",
      "\n",
      "Ambas estaciones ofrecen paisajes espectaculares y temperaturas agradables. Evita el verano si no te gusta el calor y la humedad, y ten en cuenta que el invierno puede ser frío, aunque es perfecto para esquiar o disfrutar de aguas termales.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Pregunta 2: Suena bien. ¿Qué ciudades me recomiendas visitar en un primer viaje?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mEn un primer viaje a Japón, te recomiendo visitar las siguientes ciudades, ya que ofrecen una combinación de historia, cultura, modernidad y naturaleza:\n",
      "\n",
      "1. **Tokio**: La capital de Japón es un lugar vibrante y lleno de contrastes. Aquí puedes explorar barrios modernos como Shibuya y Akihabara, disfrutar de la tranquilidad en templos como el Meiji Jingu, y probar la gastronomía local en mercados como Tsukiji. Además, Tokio es ideal para experimentar la tecnología y la vida urbana japonesa.\n",
      "\n",
      "2. **Kioto**: Es conocida como el corazón cultural de Japón. Aquí encontrarás templos impresionantes como el Kinkaku-ji (Pabellón Dorado) y el Fushimi Inari Taisha con sus famosos torii rojos. También puedes pasear por el distrito de Gion, famoso por las geishas, y disfrutar de los jardines tradicionales.\n",
      "\n",
      "3. **Osaka**: Es famosa por su ambiente animado y su gastronomía. No te pierdas el Castillo de Osaka, el barrio de Dotonbori con sus luces y restaurantes, y prueba platos típicos como el takoyaki y el okonomiyaki.\n",
      "\n",
      "4. **Nara**: A poca distancia de Kioto y Osaka, Nara es conocida por el Parque de Nara, donde puedes interactuar con ciervos que deambulan libremente, y por el Templo Todai-ji, que alberga una enorme estatua de Buda.\n",
      "\n",
      "5. **Hiroshima**: Una ciudad con una historia conmovedora. Visita el Parque Memorial de la Paz y el Museo de la Paz, y no te pierdas la isla de Miyajima cercana, famosa por su torii flotante y su belleza natural.\n",
      "\n",
      "6. **Hakone o Monte Fuji**: Si te interesa la naturaleza, Hakone es ideal para disfrutar de vistas del Monte Fuji, relajarte en un onsen (baño termal) y explorar el Lago Ashi. También puedes considerar visitar los alrededores del Monte Fuji para hacer senderismo.\n",
      "\n",
      "Estas ciudades te ofrecen una experiencia completa de Japón, desde su historia y tradiciones hasta su modernidad y paisajes naturales. ¿Te interesa alguna en particular?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Pregunta 3: ¿Sobre qué estábamos hablando?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mEstábamos hablando sobre organizar un viaje a Japón. Te mencioné las mejores épocas para visitar el país, como la primavera (marzo a mayo) por los cerezos en flor y el otoño (septiembre a noviembre) por el follaje vibrante. También te recomendé evitar el verano por el calor y la humedad, y te mencioné que el invierno es ideal para esquiar o disfrutar de los onsen (aguas termales).\n",
      "\n",
      "Además, te sugerí algunas ciudades para un primer viaje, como Tokio, Kioto, Osaka, Nara, Hiroshima y Hakone o el Monte Fuji, destacando lo que hace especial a cada lugar. ¿Te gustaría que profundicemos en alguna de estas ciudades o en otro aspecto del viaje?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Respuesta 3: Estábamos hablando sobre organizar un viaje a Japón. Te mencioné las mejores épocas para visitar el país, como la primavera (marzo a mayo) por los cerezos en flor y el otoño (septiembre a noviembre) por el follaje vibrante. También te recomendé evitar el verano por el calor y la humedad, y te mencioné que el invierno es ideal para esquiar o disfrutar de los onsen (aguas termales).\n",
      "\n",
      "Además, te sugerí algunas ciudades para un primer viaje, como Tokio, Kioto, Osaka, Nara, Hiroshima y Hakone o el Monte Fuji, destacando lo que hace especial a cada lugar. ¿Te gustaría que profundicemos en alguna de estas ciudades o en otro aspecto del viaje?\n"
     ]
    }
   ],
   "source": [
    "print(\"Pregunta 1: Necesito organizar un viaje a Japón. ¿Cuál es la mejor época para ir?\")\n",
    "chat_with_agent_summary(\"Necesito organizar un viaje a Japón. ¿Cuál es la mejor época para ir?\")\n",
    "\n",
    "print(\"Pregunta 2: Suena bien. ¿Qué ciudades me recomiendas visitar en un primer viaje?\")\n",
    "chat_with_agent_summary(\"¿Qué ciudades me recomiendas visitar en un primer viaje?\")\n",
    "\n",
    "print(\"Pregunta 3: ¿Sobre qué estábamos hablando?\")\n",
    "response3_summary = chat_with_agent_summary(\"¿Sobre qué estábamos hablando?\")\n",
    "print(f\"Respuesta 3: {response3_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El agente debería poder responder correctamente, ya que la memoria no contiene los mensajes literales, sino un resumen de que el usuario está planeando un viaje a Japón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones y Transición al Módulo IL2.3\n",
    "\n",
    "Hemos visto cómo las clases de memoria de LangChain nos permiten crear agentes conversacionales mucho más robustos y eficientes, superando los desafíos de la gestión manual y el tamaño del contexto.\n",
    "\n",
    "**Resumen de Estrategias de Memoria:**\n",
    "- **`ConversationBufferMemory`**: Simple y completa. Ideal para conversaciones cortas donde cada detalle importa.\n",
    "- **`ConversationBufferWindowMemory`**: Eficiente y balanceada. Perfecta para chatbots de servicio al cliente que necesitan contexto reciente.\n",
    "- **`ConversationSummaryMemory`**: Ahorradora de tokens y escalable. La mejor opción para asistentes de largo plazo y análisis de conversaciones extensas.\n",
    "\n",
    "Con un agente que puede recordar de manera efectiva, hemos completado una pieza fundamental del rompecabezas. Sin embargo, las conversaciones del mundo real a menudo implican tareas que no se resuelven con una sola herramienta o en un solo paso.\n",
    "\n",
    "**¿Qué pasa si el agente necesita buscar información, luego calcular algo con esa información y finalmente enviar un correo electrónico?**\n",
    "\n",
    "Esto requiere que el agente pueda **planificar** una secuencia de acciones. Debe ser capaz de descomponer un objetivo complejo en pasos más pequeños y ejecutarlos en el orden correcto.\n",
    "\n",
    "Esta es la transición perfecta al **Módulo IL2.3: Planificación y Orquestación de Agentes**, donde exploraremos cómo los agentes pueden crear, seguir y adaptar planes para resolver problemas complejos y multi-paso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
