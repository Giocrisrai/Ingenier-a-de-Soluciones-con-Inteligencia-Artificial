{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Agentes con Function Calling Nativo de OpenAI\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender el mecanismo de \"Function Calling\" de OpenAI y sus ventajas.\n",
    "- Definir herramientas en el formato JSON Schema que requiere la API.\n",
    "- Implementar un agente que utiliza function calling para interactuar con una API externa (Wikipedia).\n",
    "- Manejar el flujo de una conversaci√≥n donde el modelo solicita la ejecuci√≥n de una funci√≥n.\n",
    "\n",
    "## ¬øQu√© es Function Calling y por qu√© es mejor?\n",
    "\n",
    "En el notebook anterior, construimos un agente que funcionaba parseando texto. El LLM escrib√≠a su intenci√≥n de usar una herramienta en un formato espec√≠fico (\"Action: {...}\"), y nosotros us√°bamos expresiones regulares para extraer esa intenci√≥n. Este m√©todo funciona, pero es fr√°gil:\n",
    "\n",
    "- El LLM puede cometer errores y no generar el texto en el formato exacto.\n",
    "- El parsing puede fallar si la estructura del texto cambia ligeramente.\n",
    "- Los argumentos de la funci√≥n se pasan como un string que debemos convertir a JSON, lo cual puede dar errores.\n",
    "\n",
    "**Function Calling** es la soluci√≥n nativa de OpenAI a este problema. En lugar de pedirle al modelo que *escriba* qu√© herramienta quiere usar, le permitimos que nos devuelva una estructura de datos **JSON bien formada** que especifica el nombre de la funci√≥n y los argumentos que quiere usar. \n",
    "\n",
    "**Ventajas:**\n",
    "1.  **Fiabilidad**: El modelo est√° entrenado para generar un JSON v√°lido, eliminando casi por completo los errores de formato.\n",
    "2.  **Seguridad**: Evita la necesidad de ejecutar c√≥digo que el LLM genera directamente.\n",
    "3.  **Simplicidad**: No m√°s parsing con expresiones regulares. La intenci√≥n del modelo es clara y estructurada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instalaci√≥n y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai wikipedia -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cliente OpenAI configurado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import wikipedia\n",
    "from openai import OpenAI\n",
    "\n",
    "# Configurar el idioma de Wikipedia\n",
    "wikipedia.set_lang(\"es\")\n",
    "\n",
    "# --- Configuraci√≥n del Cliente OpenAI ---\n",
    "try:\n",
    "    client = OpenAI(\n",
    "        base_url=os.environ.get(\"GITHUB_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"GITHUB_TOKEN\")\n",
    "    )\n",
    "    print(\"‚úÖ Cliente OpenAI configurado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error configurando el cliente: {e}\")\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definici√≥n de Herramientas en formato OpenAI\n",
    "\n",
    "Primero, definimos la funci√≥n de Python que queremos que nuestro agente pueda usar. En este caso, una funci√≥n que busca un resumen en Wikipedia.\n",
    "\n",
    "Luego, y esto es lo m√°s importante, describimos esa funci√≥n en un formato de **JSON Schema**. Esta descripci√≥n le dice al LLM qu√© es la herramienta, para qu√© sirve y qu√© argumentos necesita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Herramienta y su definici√≥n para OpenAI listas.\n"
     ]
    }
   ],
   "source": [
    "# La funci√≥n de Python que realiza la acci√≥n\n",
    "def get_wikipedia_summary(query):\n",
    "    \"\"\"Busca en Wikipedia un tema y devuelve un resumen de 2 frases.\"\"\"\n",
    "    try:\n",
    "        # sentences=2 pide a la librer√≠a que devuelva un resumen de 2 frases\n",
    "        summary = wikipedia.summary(query, sentences=2)\n",
    "        return summary\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return f\"No se encontr√≥ ninguna p√°gina para '{query}'.\"\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"La b√∫squeda para '{query}' es ambigua. Opciones: {e.options[:3]}\"\n",
    "\n",
    "# Lista de herramientas en formato JSON Schema para la API de OpenAI\n",
    "tools_definition = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_wikipedia_summary\",\n",
    "            \"description\": \"Obtiene un resumen conciso de un art√≠culo de Wikipedia para un tema o persona espec√≠fica.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"El tema o nombre a buscar en Wikipedia. Por ejemplo, 'Albert Einstein'.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Herramienta y su definici√≥n para OpenAI listas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. El Flujo del Agente con Function Calling\n",
    "\n",
    "El proceso ahora es m√°s estructurado:\n",
    "\n",
    "1.  **Usuario -> Agente**: Enviamos la pregunta del usuario y la lista de herramientas (`tools_definition`) al LLM.\n",
    "2.  **LLM -> Agente**: El LLM analiza la pregunta. Si decide que necesita una herramienta, en lugar de devolver un mensaje de texto, devuelve un objeto `tool_calls`.\n",
    "3.  **Agente**: Verificamos si la respuesta contiene `tool_calls`. Si es as√≠, ejecutamos la funci√≥n correspondiente en nuestro c√≥digo Python.\n",
    "4.  **Agente -> LLM**: Enviamos el resultado de la funci√≥n de vuelta al LLM en un nuevo mensaje con `role=\"tool\"`.\n",
    "5.  **LLM -> Usuario**: El LLM, ahora con la informaci√≥n de la herramienta, genera la respuesta final en lenguaje natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ L√≥gica del agente con Function Calling definida.\n"
     ]
    }
   ],
   "source": [
    "def run_agent_with_function_calling(user_query, client, tools_definition):\n",
    "    if not client:\n",
    "        return \"Cliente no inicializado.\"\n",
    "\n",
    "    # Mapeo de nombres de funci√≥n a las funciones de Python reales\n",
    "    available_tools = {\n",
    "        \"get_wikipedia_summary\": get_wikipedia_summary,\n",
    "    }\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": user_query}]\n",
    "    \n",
    "    print(f\"--- üöÄ Iniciando agente para la consulta: '{user_query}' ---\")\n",
    "\n",
    "    # Primera llamada al modelo\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools_definition, # Aqu√≠ pasamos la definici√≥n de las herramientas\n",
    "        tool_choice=\"auto\",  # El modelo decide si usar una herramienta o no\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message) # A√±adir la respuesta del LLM al historial\n",
    "\n",
    "    # Comprobar si el modelo quiere llamar a una funci√≥n\n",
    "    if response_message.tool_calls:\n",
    "        print(\"ü§ñ El modelo ha decidido usar una herramienta...\")\n",
    "        for tool_call in response_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"   - Herramienta: {function_name}\")\n",
    "            print(f\"   - Argumentos: {function_args}\")\n",
    "            \n",
    "            # Ejecutar la funci√≥n\n",
    "            function_to_call = available_tools[function_name]\n",
    "            function_response = function_to_call(**function_args)\n",
    "            \n",
    "            print(f\"   - Resultado: {function_response}\")\n",
    "            \n",
    "            # Enviar el resultado de vuelta al modelo\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        # Segunda llamada al modelo, ahora con el resultado de la herramienta\n",
    "        print(\"üß† El modelo est√° procesando el resultado de la herramienta...\")\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages\n",
    "        )\n",
    "        return second_response.choices[0].message.content\n",
    "    else:\n",
    "        # Si el modelo no us√≥ una herramienta, devuelve su respuesta directamente\n",
    "        print(\"‚úÖ El modelo ha respondido directamente.\")\n",
    "        return response_message.content\n",
    "\n",
    "print(\"‚úÖ L√≥gica del agente con Function Calling definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ejecuci√≥n del Agente\n",
    "\n",
    "Probemos con una pregunta que claramente necesita conocimiento externo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Iniciando agente para la consulta: '¬øQui√©n fue Marie Curie y cu√°les fueron sus logros m√°s importantes?' ---\n",
      "ü§ñ El modelo ha decidido usar una herramienta...\n",
      "   - Herramienta: get_wikipedia_summary\n",
      "   - Argumentos: {'query': 'Marie Curie'}\n",
      "   - Resultado: Maria Salomea Sk≈Çodowska-Curie,‚Äã‚Äã m√°s conocida como Marie Curie‚Äã‚Äã o Madame Curie (Varsovia, 7 de noviembre de 1867-Passy, 4 de julio de 1934), fue una f√≠sica y qu√≠mica de origen polaco. Pionera en el campo de la radiactividad, es la primera y √∫nica persona en recibir dos premios Nobel en distintas especialidades cient√≠ficas: F√≠sica y Qu√≠mica.‚Äã Tambi√©n fue la primera mujer en ocupar el puesto de profesora en la Universidad de Par√≠s y la primera en recibir sepultura con honores en el Pante√≥n de Par√≠s por m√©ritos propios en 1995.‚Äã\n",
      "Naci√≥ en Varsovia, en lo que entonces era el Zarato de Polonia (territorio administrado por el Imperio ruso).\n",
      "üß† El modelo est√° procesando el resultado de la herramienta...\n",
      "üèÅ Respuesta Final del Agente:Marie Curie (1867-1934) fue una destacada f√≠sica y qu√≠mica, pionera en el campo de la radiactividad. Nacida en Varsovia, Polonia, y con una carrera desarrollada principalmente en Francia, logr√≥ importantes avances cient√≠ficos que marcaron la historia. Entre sus logros m√°s sobresalientes est√°n:\n",
      "\n",
      "1. **Dos premios Nobel**: Fue la primera persona en recibir dos premios Nobel en diferentes disciplinas cient√≠ficas: el Nobel de F√≠sica en 1903 (compartido con Pierre Curie y Henri Becquerel, por investigaciones sobre la radiactividad) y el Nobel de Qu√≠mica en 1911 (por el descubrimiento del radio y el polonio).\n",
      "\n",
      "2. **Descubrimientos revolucionarios**: Identific√≥ y estudi√≥ los elementos radiactivos polonio y radio, contribuyendo a transformar las ciencias f√≠sicas y qu√≠micas, adem√°s de abrir nuevas v√≠as para la medicina.\n",
      "\n",
      "3. **Primera profesora en la Universidad de Par√≠s**: Fue la primera mujer en ocupar una c√°tedra en esta universidad, rompiendo barreras de g√©nero en el √°mbito acad√©mico.\n",
      "\n",
      "4. **Honores excepcionales**: En 1995, se convirti√≥ en la primera mujer enterrada en el Pante√≥n de Par√≠s por m√©ritos propios, en honor a sus contribuciones cient√≠ficas.\n",
      "\n",
      "Marie Curie no solo dej√≥ un legado cient√≠fico inmenso sino que tambi√©n se convirti√≥ en un s√≠mbolo de perseverancia y dedicaci√≥n en un contexto en que ser mujer y cient√≠fica era un gran desaf√≠o.\n"
     ]
    }
   ],
   "source": [
    "query = \"¬øQui√©n fue Marie Curie y cu√°les fueron sus logros m√°s importantes?\"\n",
    "final_answer = run_agent_with_function_calling(query, client, tools_definition)\n",
    "\n",
    "print(f\"üèÅ Respuesta Final del Agente:{final_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "El uso de **Function Calling** nativo representa un salto cualitativo en la construcci√≥n de agentes. La comunicaci√≥n entre el LLM y nuestro c√≥digo es ahora mucho m√°s **robusta, predecible y f√°cil de depurar**.\n",
    "\n",
    "Hemos eliminado la necesidad de crear prompts complejos para el formato ReAct y de parsear la salida del modelo. Sin embargo, todav√≠a gestionamos manualmente el estado de la conversaci√≥n (`messages`) y el flujo de llamadas.\n",
    "\n",
    "En el pr√≥ximo notebook, introduciremos **LangChain**, un framework que abstrae esta l√≥gica y nos permite construir agentes a√∫n m√°s potentes con mucho menos c√≥digo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
