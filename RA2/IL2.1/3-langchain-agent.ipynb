{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construcción de Agentes con LangChain\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender las ventajas de usar un framework como LangChain para el desarrollo de agentes.\n",
    "- Aprender a definir herramientas (Tools) de forma sencilla con el decorador `@tool`.\n",
    "- Crear un agente utilizando el constructor `create_openai_tools_agent`.\n",
    "- Ejecutar el agente y gestionar la interacción mediante el `AgentExecutor`.\n",
    "\n",
    "## ¿Por qué usar LangChain?\n",
    "\n",
    "En los notebooks anteriores, construimos agentes desde cero. Primero, parseando texto, y luego, usando `function calling` nativo. Aunque el `function calling` es una gran mejora, todavía teníamos que:\n",
    "\n",
    "1.  **Gestionar el historial de mensajes (`messages`) manualmente**: Añadir cada respuesta del usuario, del asistente y de la herramienta a la lista.\n",
    "2.  **Orquestar el flujo de llamadas**: Escribir la lógica `if/else` para decidir si llamar a una herramienta, ejecutarla y volver a llamar al modelo.\n",
    "3.  **Formatear las herramientas**: Escribir el JSON Schema para cada herramienta, lo cual es propenso a errores.\n",
    "\n",
    "**LangChain** es un framework que abstrae toda esta complejidad. Actúa como una capa intermedia que simplifica enormemente la creación de aplicaciones basadas en LLMs, incluyendo los agentes. \n",
    "\n",
    "**Ventajas clave:**\n",
    "- **Componentes Modulares**: Ofrece piezas reutilizables (LLMs, Prompts, Herramientas, etc.) que se pueden ensamblar fácilmente.\n",
    "- **Agentes Listos para Usar**: Proporciona abstracciones de alto nivel como el `AgentExecutor` que manejan el ciclo de razonamiento (ReAct) por nosotros.\n",
    "- **Integraciones**: Se conecta con cientos de fuentes de datos, APIs y otros servicios de forma nativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instalación y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai openai wikipedia -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM de LangChain configurado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wikipedia\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Configurar el idioma de Wikipedia\n",
    "wikipedia.set_lang('es')\n",
    "\n",
    "# --- Configuración del LLM con LangChain ---\n",
    "# LangChain actúa como un \"envoltorio\" (wrapper) sobre el cliente de OpenAI\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        openai_api_base=os.environ.get(\"GITHUB_BASE_URL\"),\n",
    "        openai_api_key=os.environ.get(\"GITHUB_TOKEN\"),\n",
    "        temperature=0\n",
    "    )\n",
    "    print(\"✅ LLM de LangChain configurado.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error configurando el LLM: {e}\")\n",
    "    llm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definición de Herramientas con LangChain\n",
    "\n",
    "LangChain simplifica enormemente la creación de herramientas. En lugar de escribir un JSON Schema manual, simplemente usamos el decorador `@tool` sobre una función de Python. LangChain se encarga de inferir el esquema a partir de la firma de la función y su docstring.\n",
    "\n",
    "El docstring es **muy importante**, ya que se usa como la descripción que el LLM ve para decidir si usar la herramienta o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Herramientas de LangChain definidas.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_wikipedia_summary(query: str) -> str:\n",
    "    \"\"\"Busca en Wikipedia un tema y devuelve un resumen de 2 frases. Es ideal para obtener información sobre personas, lugares o conceptos históricos y científicos.\"\"\"\n",
    "    try:\n",
    "        summary = wikipedia.summary(query, sentences=2)\n",
    "        return summary\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return f\"No se encontró ninguna página para '{query}'.\"\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"La búsqueda para '{query}' es ambigua. Opciones: {e.options[:3]}\"\n",
    "\n",
    "tools = [get_wikipedia_summary]\n",
    "\n",
    "print(\"✅ Herramientas de LangChain definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creación del Agente\n",
    "\n",
    "Para crear el agente, necesitamos dos cosas:\n",
    "\n",
    "1.  **Un Prompt**: Una plantilla que le dice al agente cómo razonar y cómo usar las herramientas. LangChain ya tiene prompts pre-construidos y optimizados para esto. Usaremos `hub.pull(\"hwchase17/openai-functions-agent\")` para obtener una plantilla probada.\n",
    "2.  **El Agente en sí**: Usamos la función `create_openai_tools_agent`, que une el LLM, las herramientas y el prompt.\n",
    "\n",
    "El resultado es un `Runnable` de LangChain, que es el agente listo para ser ejecutado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Agente de LangChain creado.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "\n",
    "# Descargar un prompt pre-diseñado y optimizado para agentes con function calling\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# Unir el LLM, las herramientas y el prompt para crear el agente\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "print(\"✅ Agente de LangChain creado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ejecución del Agente con `AgentExecutor`\n",
    "\n",
    "El `agent` que creamos en el paso anterior es solo el \"cerebro\". Sabe cómo razonar, pero no puede ejecutar el ciclo de `Pensamiento -> Acción -> Observación` por sí mismo.\n",
    "\n",
    "Para eso, usamos el **`AgentExecutor`**. Esta clase toma el agente y las herramientas, y se encarga de toda la orquestación:\n",
    "\n",
    "- Llama al agente con la entrada del usuario.\n",
    "- Si el agente decide usar una herramienta, el `AgentExecutor` la ejecuta.\n",
    "- Pasa el resultado de la herramienta de vuelta al agente.\n",
    "- Repite el proceso hasta que el agente da una respuesta final.\n",
    "- Gestiona el historial de la conversación (`chat_history`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AgentExecutor listo para funcionar.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"✅ AgentExecutor listo para funcionar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Invocando al Agente\n",
    "\n",
    "Ahora, simplemente llamamos al método `invoke` del `agent_executor` con la pregunta. El parámetro `chat_history` es opcional pero útil para conversaciones de seguimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_wikipedia_summary` with `{'query': 'Marie Curie'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mMaria Salomea Skłodowska-Curie,​​ más conocida como Marie Curie​​ o Madame Curie (Varsovia, 7 de noviembre de 1867-Passy, 4 de julio de 1934), fue una física y química de origen polaco. Pionera en el campo de la radiactividad, es la primera y única persona en recibir dos premios Nobel en distintas especialidades científicas: Física y Química.​ También fue la primera mujer en ocupar el puesto de profesora en la Universidad de París y la primera en recibir sepultura con honores en el Panteón de París por méritos propios en 1995.​\n",
      "Nació en Varsovia, en lo que entonces era el Zarato de Polonia (territorio administrado por el Imperio ruso).\u001b[0m\u001b[32;1m\u001b[1;3mMarie Curie fue una física y química polaca, pionera en el campo de la radiactividad. Es reconocida como la primera persona en recibir dos premios Nobel en distintas especialidades científicas: Física y Química. Además, fue la primera mujer en ser profesora en la Universidad de París y en recibir sepultura con honores en el Panteón de París por méritos propios.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🏁 Respuesta Final del Agente: {'input': '¿Quién fue Marie Curie y cuáles fueron sus logros más importantes?', 'chat_history': [], 'output': 'Marie Curie fue una física y química polaca, pionera en el campo de la radiactividad. Es reconocida como la primera persona en recibir dos premios Nobel en distintas especialidades científicas: Física y Química. Además, fue la primera mujer en ser profesora en la Universidad de París y en recibir sepultura con honores en el Panteón de París por méritos propios.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"¿Quién fue Marie Curie y cuáles fueron sus logros más importantes?\"\n",
    "\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": query,\n",
    "    \"chat_history\": []\n",
    "})\n",
    "\n",
    "print(f\"🏁 Respuesta Final del Agente: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Como hemos visto, LangChain reduce drásticamente la cantidad de código repetitivo y la complejidad de construir un agente. Nos hemos podido centrar en:\n",
    "\n",
    "1.  **Definir la lógica de la herramienta**: La función `get_wikipedia_summary`.\n",
    "2.  **Ensamblar los componentes**: Unir el LLM, las herramientas y un prompt usando las abstracciones de LangChain.\n",
    "\n",
    "El `AgentExecutor` se encargó de todo el ciclo de ejecución, el manejo de estado y la orquestación, que antes teníamos que programar manualmente.\n",
    "\n",
    "En el siguiente notebook, exploraremos **CrewAI**, otro framework de alto nivel que se especializa en la creación de equipos de agentes que colaboran para resolver tareas aún más complejas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
